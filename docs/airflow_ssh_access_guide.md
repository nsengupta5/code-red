# Airflow on GCE – Setup & SSH Access Guide

This document describes how Apache Airflow is deployed on a Google Compute Engine (GCE) VM using Terraform, and how administrators can securely access the Airflow UI via an SSH tunnel.

---

## 1. Architecture Overview

- **Compute**: Single GCE VM
- **Airflow Version**: Installed via `pip` in a Python virtual environment
- **Executor**: SequentialExecutor (SQLite-backed, dev-only)
- **Metadata DB**: SQLite (local to VM)
- **Networking**:
  - Port 22 (SSH): Open to restricted source ranges
  - Port 8080 (Airflow UI): **Not publicly exposed**
- **Access Pattern**: SSH tunnel only

```
Laptop ──SSH──▶ GCE VM
               └── Airflow Webserver (localhost:8080)
```

---

## 2. How Airflow Is Installed

Airflow is installed automatically at VM boot via a **startup script** generated by Terraform.

Key steps performed by the startup script:

1. Install OS dependencies (Python, build tools, SQLite, etc.)
2. Create directories:
   - `/opt/airflow`
   - `/opt/airflow/dags`
   - `/opt/airflow/venv`
3. Create Python virtual environment
4. Install Apache Airflow (version pinned via Terraform variable)
5. Initialize the Airflow metadata database
6. Create an admin user (credentials sourced from Secret Manager)
7. Register and start systemd services:
   - `airflow-webserver`
   - `airflow-scheduler`

Environment configuration is written to:

```
/etc/airflow.env
```

---

## 3. Airflow Services

Two systemd services are installed:

### Webserver
```bash
sudo systemctl status airflow-webserver
```

### Scheduler
```bash
sudo systemctl status airflow-scheduler
```

Logs:
```bash
journalctl -u airflow-webserver
journalctl -u airflow-scheduler
```

---

## 4. Network Security Model

### What is allowed
- SSH (port 22) from approved CIDR ranges only

### What is blocked
- Direct access to Airflow UI (port 8080) from the internet

This ensures Airflow is **not publicly exposed**.

---

## 5. Accessing the Airflow UI (Admins)

### Step 1: Open an SSH tunnel

Run this **from your local machine**:

```bash
gcloud compute ssh airflow-dev \
  --project YOUR_PROJECT_ID \
  --zone YOUR_ZONE \
  -- -L 8080:localhost:8080
```

Keep this terminal open.

---

### Step 2: Open the UI in your browser

Visit:

```
http://localhost:8080
```

The traffic is securely forwarded through SSH to the VM.

---

## 6. Airflow Login Credentials

- **Username**: Defined in Terraform (`airflow_admin_username`)
- **Password**: Stored in Google Secret Manager and injected at boot

If credentials need to be recreated:

```bash
source /opt/airflow/venv/bin/activate
export AIRFLOW_HOME=/opt/airflow

airflow users create \
  --username admin \
  --password NEW_PASSWORD \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com
```

---

## 7. Why SSH Tunnel Access Was Chosen

This approach was selected because it:

- Avoids exposing Airflow publicly
- Does not require Google Workspace or IAP
- Works with standard Gmail accounts
- Is ideal for dev / trial environments
- Keeps infrastructure simple and secure

---

## 8. Production Considerations (Future)

For production usage, consider:

- Moving metadata DB to **Cloud SQL (Postgres)**
- Using **LocalExecutor / CeleryExecutor**
- Enabling **IAP** (requires Workspace)
- Migrating to **Cloud Composer**

---

## 9. Summary

✔ Airflow runs automatically on VM boot  
✔ UI is private and secure  
✔ Admin access via SSH tunnel  
✔ Minimal cost and complexity  

This setup is well-suited for development and experimentation.
