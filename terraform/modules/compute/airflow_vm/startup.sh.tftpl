#!/usr/bin/env bash
set -euo pipefail

#######################################
# Variables injected by Terraform
#######################################
AIRFLOW_VERSION="${airflow_version}"
PY_CONSTRAINTS="${python_constraints_version}"
CONSTRAINTS_URL="${constraints_url}"

AIRFLOW_HOME="${airflow_home}"
VENV_DIR="${venv_dir}"
DAGS_DIR="${dags_dir}"

EXECUTOR="${airflow_executor}"
WEBSERVER_PORT="${airflow_webserver_port}"

ADMIN_USER="${airflow_admin_username}"
ADMIN_PASS="${airflow_admin_password}"
ADMIN_FN="${airflow_admin_firstname}"
ADMIN_LN="${airflow_admin_lastname}"
ADMIN_EMAIL="${airflow_admin_email}"

INSTALL_PROVIDERS_GOOGLE="${install_providers_google}"

# OPTIONAL: set this to empty string if you donâ€™t want DAG sync
DAG_GCS_BUCKET="${dag_gcs_bucket}"


#######################################
# OS packages
#######################################
echo "[startup] Installing OS packages..."
apt-get update -y
apt-get install -y --no-install-recommends \
  python3 python3-venv python3-pip \
  build-essential curl ca-certificates \
  sqlite3 \
  git \
  google-cloud-sdk


#######################################
# DAG sync script (hash-based)
#######################################
echo "[startup] Installing DAG sync script..."

cat >/usr/local/bin/sync-airflow-dags.sh <<'EOF'
${sync_script}
EOF
chmod +x /usr/local/bin/sync-airflow-dags.sh

# Provide config to the script via env file
cat >/etc/airflow-dag-sync.env <<EOF
DAG_BUCKET_URI=${dag_gcs_bucket}
DAGS_DIR=${dags_dir}
EOF

# systemd unit
cat >/etc/systemd/system/airflow-dag-sync.service <<'EOF'
[Unit]
Description=Sync Airflow DAGs from GCS (hash-based)
After=network-online.target
Wants=network-online.target

[Service]
Type=oneshot
EnvironmentFile=/etc/airflow-dag-sync.env
ExecStart=/usr/local/bin/sync-airflow-dags.sh
EOF

# systemd timer (every 2 minutes; adjust as desired)
cat >/etc/systemd/system/airflow-dag-sync.timer <<'EOF'
[Unit]
Description=Periodic DAG sync from GCS

[Timer]
OnBootSec=30
OnUnitActiveSec=2min
AccuracySec=30s
Persistent=true

[Install]
WantedBy=timers.target
EOF

systemctl daemon-reload
systemctl enable --now airflow-dag-sync.timer

# Run once immediately so the first boot gets DAGs right away
echo "[startup] Running initial DAG sync..."
systemctl start airflow-dag-sync.service || true


#######################################
# Directory setup
#######################################
echo "[startup] Creating Airflow directories..."
mkdir -p "${airflow_home}" "${dags_dir}"
chmod -R 755 "${airflow_home}"

#######################################
# Python virtualenv
#######################################
echo "[startup] Creating virtualenv..."
if [ ! -d "${venv_dir}" ]; then
  python3 -m venv "${venv_dir}"
fi

# shellcheck disable=SC1090
source "${venv_dir}/bin/activate"
python -m pip install --upgrade pip setuptools wheel

#######################################
# Install Airflow
#######################################
echo "[startup] Installing Apache Airflow ${airflow_version}..."
pip install "apache-airflow==${airflow_version}" --constraint "${constraints_url}"

if [ "${install_providers_google}" = "true" ]; then
  echo "[startup] Installing Google provider..."
  pip install "apache-airflow-providers-google" --constraint "${constraints_url}"
fi

#######################################
# Sync DAGs from GCS
#######################################

DAG_BUCKET="${dag_gcs_bucket}"

if [ -n "${dag_gcs_bucket}" ]; then
  echo "[startup] Syncing DAGs from gs://${dag_gcs_bucket}..." | tee -a /var/log/airflow-startup.log

  mkdir -p /opt/airflow/dags

  gsutil rsync -r "gs://${dag_gcs_bucket}/dags" /opt/airflow/dags \
    | tee -a /var/log/airflow-startup.log

  chmod -R 755 /opt/airflow/dags
else
  echo "[startup] No DAG bucket configured; skipping DAG sync" \
    | tee -a /var/log/airflow-startup.log
fi



#######################################
# Airflow environment file
#######################################
echo "[startup] Writing /etc/airflow.env..."

cat >/etc/airflow.env <<EOF
AIRFLOW_HOME=${airflow_home}
AIRFLOW__CORE__DAGS_FOLDER=${dags_dir}
AIRFLOW__CORE__EXECUTOR=${airflow_executor}
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
AIRFLOW__WEBSERVER__WEB_SERVER_PORT=${airflow_webserver_port}
EOF

#######################################
# Export env for CLI usage
#######################################
export AIRFLOW_HOME="${airflow_home}"
export AIRFLOW__CORE__DAGS_FOLDER="${dags_dir}"
export AIRFLOW__CORE__EXECUTOR="${airflow_executor}"
export AIRFLOW__CORE__LOAD_EXAMPLES=False
export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN="sqlite:////opt/airflow/airflow.db"
export AIRFLOW__WEBSERVER__WEB_SERVER_PORT="${airflow_webserver_port}"

#######################################
# Initialize DB (idempotent)
#######################################
echo "[startup] Initializing Airflow DB..."
airflow db init || true

#######################################
# Create admin user (idempotent)
#######################################
echo "[startup] Creating admin user..."
airflow users create \
  --username "${airflow_admin_username}" \
  --password "${airflow_admin_password}" \
  --firstname "${airflow_admin_firstname}" \
  --lastname "${airflow_admin_lastname}" \
  --role Admin \
  --email "${airflow_admin_email}" || true

#######################################
# systemd services
#######################################
echo "[startup] Writing systemd units..."

cat >/etc/systemd/system/airflow-webserver.service <<EOF
[Unit]
Description=Airflow webserver
After=network.target

[Service]
Type=simple
EnvironmentFile=/etc/airflow.env
WorkingDirectory=/opt/airflow
ExecStart=/opt/airflow/venv/bin/airflow webserver
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF

cat >/etc/systemd/system/airflow-scheduler.service <<EOF
[Unit]
Description=Airflow scheduler
After=network.target

[Service]
Type=simple
EnvironmentFile=/etc/airflow.env
WorkingDirectory=/opt/airflow
ExecStart=/opt/airflow/venv/bin/airflow scheduler
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF

#######################################
# Start services
#######################################
systemctl daemon-reexec
systemctl daemon-reload
systemctl enable airflow-webserver airflow-scheduler
systemctl restart airflow-webserver airflow-scheduler

#######################################
# Done
#######################################
echo "[startup] Airflow installation complete."
echo "[startup] Web UI on port ${airflow_webserver_port}"
